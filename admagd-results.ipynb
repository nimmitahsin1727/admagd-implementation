{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMAGD - Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"tfidf_train_extra_stopwords_admagd_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"trained_ model/{model_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_path}.pkl\", 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_joblib = load(f\"{model_path}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_topic_word_distribution(model):\n",
    "#     phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "#     for topic_idx in range(model.num_topics):\n",
    "#         print(f\"Topic #{topic_idx+1}:\\n\")\n",
    "        \n",
    "#         for word_id in range(model.vocab_size):\n",
    "#             word_probability = phi[topic_idx, word_id]\n",
    "#             word = model.id2word[word_id]\n",
    "#             print(f\"{word}: {word_probability:.4f}\")\n",
    "        \n",
    "#         print(\"\\n\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# print_topic_word_distribution(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words_per_topic(model, top_n=10):\n",
    "    phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "    for topic_idx in range(model.num_topics):\n",
    "        print(f\"<< Topic # {topic_idx+1} >>\")\n",
    "\n",
    "        # Get the top N word indices for the topic sorted by probability\n",
    "        top_word_indices = phi[topic_idx].argsort()[-top_n:][::-1]\n",
    "        \n",
    "        for word_id in top_word_indices:\n",
    "            word_probability = phi[topic_idx, word_id]\n",
    "            word = model.id2word[word_id]\n",
    "            print(f\"{word}: {word_probability:.4f}\")\n",
    "\n",
    "        print(\"\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# After running your model...\n",
    "# print_top_words_per_topic(loaded_model, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you've run Gibbs sampling\n",
    "word_topic_matrix = loaded_model.word_topic_matrix\n",
    "word_topic_sum = word_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "word_topic_dist = word_topic_matrix / word_topic_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: look, car, good, year, new, buy, really, work, thing, way, lot, old, let, people, right, little, drive, post, tell, price, probably, problem, try, include, great, pay, number, read, ask, bike, point, run, big, money, sure, help, offer, deal, light, wrong, sell, kind, course, leave, email, sale, question, long, pretty, far \n",
      "\n",
      "Topic 2: work, problem, window, card, drive, run, driver, email, try, program, file, disk, look, good, windows, new, memory, software, support, set, version, video, thing, machine, mode, computer, post, help, buy, bit, monitor, ram, color, interested, tell, way, graphic, include, sure, read, bus, question, follow, different, write, change, ide, screen, controller, instal \n",
      "\n",
      "Topic 3: work, problem, run, try, thing, good, way, new, program, help, look, really, chip, bit, number, window, question, available, people, line, high, speed, set, application, follow, sure, change, able, place, sell, post, send, include, email, write, card, list, right, user, best, possible, probably, tell, check, version, case, machine, information, consider, buy \n",
      "\n",
      "Topic 4: people, good, right, mean, thing, year, tell, fact, believe, way, lot, work, sure, clinton, point, actually, new, case, really, state, try, let, look, day, post, government, long, law, bad, bit, pay, article, tax, talk, real, little, follow, hold, kind, probably, start, course, big, second, term, care, far, leave, ask, result \n",
      "\n",
      "Topic 5: work, email, problem, new, drive, help, try, computer, look, good, software, card, program, buy, run, send, hard, disk, mac, question, sell, include, appreciate, memory, chip, advance, way, window, sale, board, available, power, thing, file, set, ask, data, price, old, port, sound, year, sure, machine, follow, fine, right, bit, offer, tell \n",
      "\n",
      "Topic 6: file, program, email, run, problem, look, window, post, work, available, line, help, software, include, follow, information, code, set, user, list, version, try, application, write, new, ftp, question, address, send, machine, computer, change, server, support, read, internet, number, group, graphic, function, source, display, mail, unix, provide, good, image, format, type, way \n",
      "\n",
      "Topic 7: people, kill, state, year, government, child, right, armenian, war, live, world, turkish, attack, arm, woman, country, military, happen, serdar, history, argic, force, land, today, leave, hand, place, million, muslim, home, day, number, murder, begin, try, army, report, city, armenia, thousand, town, soldier, new, event, return, population, write, away, start, course \n",
      "\n",
      "Topic 8: space, year, new, high, day, look, work, launch, nasa, cost, way, build, large, data, send, program, thing, small, orbit, earth, week, project, read, flight, good, book, application, problem, research, science, moon, low, include, old, mission, different, people, shuttle, design, real, information, technology, world, number, sun, development, place, long, rocket, support \n",
      "\n",
      "Topic 9: people, right, thing, gun, good, case, way, point, government, law, mean, state, try, reason, problem, question, work, look, weapon, tell, sure, let, really, probably, lot, course, believe, year, day, actually, crime, yes, place, fact, bad, able, quite, little, post, country, happen, allow, control, carry, consider, claim, start, talk, note, criminal \n",
      "\n",
      "Topic 10: year, good, game, team, player, look, play, way, run, start, thing, bad, point, day, really, best, win, people, right, work, new, hit, probably, second, lose, baseball, sure, believe, fan, great, season, big, lot, league, little, maybe, high, tell, problem, mean, pitch, try, hockey, average, old, pick, far, let, pretty, end \n",
      "\n",
      "Topic 11: good, look, thing, year, right, new, problem, people, way, bike, leave, day, try, really, point, work, car, bad, drive, run, case, head, great, turn, sure, start, big, tell, hand, buy, let, long, fact, help, ride, sell, email, mean, away, actually, little, maybe, old, ask, probably, ago, hit, idea, end, lot \n",
      "\n",
      "Topic 12: people, cause, good, problem, work, case, year, group, effect, look, new, question, try, really, doctor, read, start, food, disease, patient, probably, run, medical, believe, lot, information, person, study, article, test, treatment, possible, sure, result, hope, post, high, medicine, help, small, health, available, ago, set, scientific, actually, thing, research, treat, drug \n",
      "\n",
      "Topic 13: key, encryption, chip, soon, bank, clipper, government, geb, people, surrender, skepticism, gordon, secure, chastity, intellect, njxp, cadredslpittedu, shameful, year, nsa, phone, good, way, secret, work, security, encrypt, algorithm, probably, read, law, public, really, bit, right, new, privacy, agency, question, sure, escrow, try, idea, regard, example, crypto, strong, information, number, let \n",
      "\n",
      "Topic 14: good, work, look, new, power, email, try, problem, thing, help, question, drive, run, high, speed, post, way, year, big, really, phone, low, condition, long, little, include, start, available, course, unless, ask, consider, price, actually, offer, car, lot, control, buy, contact, day, appreciate, case, information, line, computer, able, small, list, software \n",
      "\n",
      "Topic 15: god, live, jesus, work, christ, people, really, way, life, right, believe, father, great, day, good, thing, place, son, talk, new, follow, word, church, long, end, post, sin, faith, mean, problem, paul, look, hold, man, world, tell, love, christian, away, try, question, hand, read, child, help, order, answer, year, fact, write \n",
      "\n",
      "Topic 16: people, israel, israeli, try, look, right, way, question, arab, post, tell, thing, work, problem, run, help, good, let, write, jew, year, believe, peace, read, probably, lebanon, sure, palestinian, fact, control, case, really, happen, group, kill, program, set, new, lot, state, attack, place, drive, send, ask, leave, force, hope, window, include \n",
      "\n",
      "Topic 17: people, point, mean, thing, way, reason, believe, good, argument, try, religion, god, word, claim, agree, true, case, post, read, question, wrong, example, exist, accept, consider, different, fact, human, life, world, christian, tell, follow, assume, matter, person, right, really, understand, ask, idea, law, course, mind, belief, view, simply, base, statement, important \n",
      "\n",
      "Topic 18: god, people, believe, christian, point, way, jesus, tell, thing, bible, good, look, question, try, read, word, mean, write, fact, reason, work, right, really, let, man, christ, course, follow, yes, truth, ask, claim, example, human, far, book, year, post, life, belief, sure, history, church, agree, quote, bad, especially, faith, statement, actually \n",
      "\n",
      "Topic 19: national, state, public, include, provide, office, government, united, individual, april, new, american, official, release, member, service, press, area, continue, force, white, plan, year, policy, house, today, base, future, department, organization, address, low, contact, community, information, major, york, lead, create, number, center, report, washington, increase, california, problem, note, addition, program, political \n",
      "\n",
      "Topic 20: game, team, play, new, year, player, good, season, league, win, look, playoff, ranger, score, hockey, nhl, post, let, goal, great, end, email, start, san, run, king, toronto, chicago, wing, pittsburgh, second, cup, best, fan, tell, john, shot, try, pick, lose, point, red, right, send, way, blue, really, city, mike, list \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the top N words for each topic\n",
    "N_TOP_WORDS = 50\n",
    "\n",
    "ALL_TOPIC_WORDS = []\n",
    "for i in range(loaded_model.num_topics):\n",
    "    top_words_idx = word_topic_dist[i].argsort()[-N_TOP_WORDS:][::-1]\n",
    "    top_words = [loaded_model.id2word[idx] for idx in top_words_idx]\n",
    "\n",
    "    ALL_TOPIC_WORDS.append(top_words)\n",
    "\n",
    "    print(f\"Topic {i + 1}: {', '.join(top_words)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the author-topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the author_topic_matrix to get author-topic distribution\n",
    "\n",
    "# Compute the sum of rows in author_topic_matrix\n",
    "author_topic_sum = loaded_model.author_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Replace zero sums with a small epsilon value\n",
    "epsilon = 1e-10\n",
    "author_topic_sum[author_topic_sum == 0] = epsilon\n",
    "\n",
    "# Perform element-wise division\n",
    "author_topic_dist = loaded_model.author_topic_matrix / author_topic_sum\n",
    "\n",
    "# Visualize the top N topics for each author\n",
    "N_TOP_TOPICS = 2\n",
    "top_topics_list = []\n",
    "for i, author in enumerate(loaded_model.authors):\n",
    "    top_topics_idx = author_topic_dist[i].argsort()[-N_TOP_TOPICS:][::-1]\n",
    "    top_topics_list.append(top_topics_idx)\n",
    "    # print(f\"Author {i+1} => {author} : Topic IDs {top_topics_idx} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lerxst@wam.umd.edu (where's my thing)</td>\n",
       "      <td>[9, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guykuo@carson.u.washington.edu (Guy Kuo)</td>\n",
       "      <td>[4, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twillis@ec.ecn.purdue.edu (Thomas E Willis)</td>\n",
       "      <td>[9, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgreen@amber (Joe Green)</td>\n",
       "      <td>[16, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcm@head-cfa.harvard.edu (Jonathan McDowell)</td>\n",
       "      <td>[3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>bchuang@css.itd.umich.edu (Ben Chuang)</td>\n",
       "      <td>[5, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>shaig@composer.think.com (Shai Guday)</td>\n",
       "      <td>[15, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>mrj@cs.su.oz.au (Mark James)</td>\n",
       "      <td>[19, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>ebodin@pearl.tufts.edu</td>\n",
       "      <td>[1, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>gunning@cco.caltech.edu (Kevin J. Gunning)</td>\n",
       "      <td>[10, 19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5769 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           authors    topics\n",
       "0            lerxst@wam.umd.edu (where's my thing)   [9, 11]\n",
       "1         guykuo@carson.u.washington.edu (Guy Kuo)    [4, 1]\n",
       "2      twillis@ec.ecn.purdue.edu (Thomas E Willis)   [9, 15]\n",
       "3                         jgreen@amber (Joe Green)  [16, 19]\n",
       "4     jcm@head-cfa.harvard.edu (Jonathan McDowell)    [3, 1]\n",
       "...                                            ...       ...\n",
       "5764        bchuang@css.itd.umich.edu (Ben Chuang)   [5, 13]\n",
       "5765         shaig@composer.think.com (Shai Guday)  [15, 18]\n",
       "5766                  mrj@cs.su.oz.au (Mark James)  [19, 18]\n",
       "5767                        ebodin@pearl.tufts.edu   [1, 19]\n",
       "5768    gunning@cco.caltech.edu (Kevin J. Gunning)  [10, 19]\n",
       "\n",
       "[5769 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df = pd.DataFrame({'authors': loaded_model.authors, 'topics': top_topics_list})\n",
    "top_topics_of_authors_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMAGD - Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"tfidf_train_extra_stopwords_200_iteration_admagd_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"trained_ model/{model_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_path}.pkl\", 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_joblib = load(f\"{model_path}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_topic_word_distribution(model):\n",
    "#     phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "#     for topic_idx in range(model.num_topics):\n",
    "#         print(f\"Topic #{topic_idx+1}:\\n\")\n",
    "        \n",
    "#         for word_id in range(model.vocab_size):\n",
    "#             word_probability = phi[topic_idx, word_id]\n",
    "#             word = model.id2word[word_id]\n",
    "#             print(f\"{word}: {word_probability:.4f}\")\n",
    "        \n",
    "#         print(\"\\n\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# print_topic_word_distribution(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words_per_topic(model, top_n=10):\n",
    "    phi = model.calculate_phi_update()  # This gives you the word-topic matrix\n",
    "\n",
    "    for topic_idx in range(model.num_topics):\n",
    "        print(f\"<< Topic # {topic_idx+1} >>\")\n",
    "\n",
    "        # Get the top N word indices for the topic sorted by probability\n",
    "        top_word_indices = phi[topic_idx].argsort()[-top_n:][::-1]\n",
    "        \n",
    "        for word_id in top_word_indices:\n",
    "            word_probability = phi[topic_idx, word_id]\n",
    "            word = model.id2word[word_id]\n",
    "            print(f\"{word}: {word_probability:.4f}\")\n",
    "\n",
    "        print(\"\\n\")  # Print a newline to separate topics\n",
    "\n",
    "# After running your model...\n",
    "# print_top_words_per_topic(loaded_model, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you've run Gibbs sampling\n",
    "word_topic_matrix = loaded_model.word_topic_matrix\n",
    "word_topic_sum = word_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "word_topic_dist = word_topic_matrix / word_topic_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: window, run, file, problem, work, program, try, look, help, write, set, windows, way, thing, good, error, new, line, server, question, follow, code, application, version, color, machine, start, driver, manager, image, let, change, case, display, type, screen, appreciate, directory, create, user, tell, bit, client, support, different, people, number, example, command, email \n",
      "\n",
      "Topic 2: year, space, new, research, development, science, information, world, program, work, report, provide, cost, base, right, center, public, high, earth, place, send, available, number, people, date, plan, sure, start, orbit, international, follow, second, contact, money, project, april, end, include, limit, begin, day, write, press, national, material, technology, reach, increase, long, analysis \n",
      "\n",
      "Topic 3: good, look, car, year, thing, really, way, right, bike, work, try, new, drive, people, sure, turn, little, tell, point, line, problem, big, lot, day, far, dod, leave, power, probably, bit, bad, rid, buy, post, large, start, road, run, ride, let, guy, best, case, end, mean, head, stuff, maybe, actually, help \n",
      "\n",
      "Topic 4: people, believe, point, good, way, mean, thing, try, god, tell, reason, life, really, post, wrong, agree, word, question, read, live, case, right, feel, probably, look, problem, talk, human, true, actually, let, fact, state, understand, idea, start, bad, day, long, example, write, work, argument, year, course, kill, mind, lot, consider, yes \n",
      "\n",
      "Topic 5: people, israel, right, state, israeli, country, jew, arab, good, way, try, government, kill, war, year, let, thing, case, fact, live, attack, claim, mean, tell, point, jewish, post, course, palestinian, land, look, start, leave, act, peace, far, stop, group, place, talk, accept, allow, really, happen, law, policy, american, work, true, world \n",
      "\n",
      "Topic 6: work, problem, drive, card, window, run, look, try, help, file, email, bit, program, new, way, computer, support, disk, set, video, driver, machine, memory, hard, controller, monitor, include, good, software, thing, bus, price, available, version, interested, scsi, speed, year, number, access, follow, sell, buy, base, windows, data, apple, post, mean, right \n",
      "\n",
      "Topic 7: god, christian, people, jesus, thing, believe, bible, question, way, good, fact, point, write, mean, claim, true, word, christ, read, church, ask, follow, world, really, faith, life, religion, answer, problem, try, tell, man, belief, right, reason, work, example, book, person, new, christianity, truth, sin, matter, john, look, different, case, post, scripture \n",
      "\n",
      "Topic 8: key, encryption, chip, people, soon, bank, government, right, law, clipper, secure, phone, gordon, geb, surrender, intellect, skepticism, njxp, chastity, good, cadredslpittedu, work, shameful, security, public, new, secret, way, nsa, probably, encrypt, sure, provide, mean, thing, bit, information, escrow, question, really, agency, number, algorithm, year, strong, try, privacy, case, long, course \n",
      "\n",
      "Topic 9: work, problem, look, new, email, thing, mac, program, run, way, card, chip, bit, buy, speed, tell, mhz, good, number, try, sell, point, read, help, software, really, drive, available, window, device, right, cost, mean, fast, high, power, question, university, write, consider, memory, machine, set, apple, include, list, price, sure, change, color \n",
      "\n",
      "Topic 10: email, software, send, computer, list, ftp, include, mail, work, help, file, post, address, look, problem, program, copy, available, advance, follow, internet, run, archivename, ask, site, new, various, application, write, add, information, source, book, function, version, require, university, number, faq, free, card, set, data, anonymous, unix, disk, info, try, format, print \n",
      "\n",
      "Topic 11: work, problem, email, try, run, look, good, window, new, help, card, program, drive, post, buy, thing, question, line, software, tell, include, disk, appreciate, windows, file, computer, set, way, information, graphic, interested, version, hardware, follow, ask, driver, bit, application, read, advance, number, memory, board, send, mac, machine, really, address, box, sell \n",
      "\n",
      "Topic 12: good, year, people, problem, thing, tell, look, way, work, try, lot, right, really, question, run, high, actually, big, old, start, great, let, sure, post, change, new, course, bad, believe, help, happen, real, live, maybe, long, case, game, read, buy, day, little, point, sound, small, leave, include, kind, power, bit, probably \n",
      "\n",
      "Topic 13: people, state, government, law, year, right, thing, case, gun, question, mean, fact, country, control, reason, person, public, tell, support, way, new, force, consider, problem, work, crime, national, let, follow, try, provide, issue, care, number, arm, believe, ask, course, american, pay, regard, protect, citizen, president, point, weapon, day, federal, note, police \n",
      "\n",
      "Topic 14: game, team, year, good, player, play, season, league, look, run, win, point, score, way, best, let, bad, fan, start, hockey, right, hit, really, baseball, lot, new, great, thing, probably, little, pick, lose, end, second, pitch, day, maybe, home, nhl, guy, long, people, number, watch, post, ranger, playoff, average, actually, big \n",
      "\n",
      "Topic 15: look, work, good, new, thing, email, include, information, run, best, power, try, data, help, post, available, problem, probably, offer, condition, car, old, space, way, drive, read, low, buy, year, control, model, sell, end, cost, set, long, image, advance, lot, light, little, ask, sale, sound, source, program, price, radio, design, file \n",
      "\n",
      "Topic 16: armenian, kill, government, people, child, turkish, year, world, serdar, argic, begin, source, war, armenia, away, woman, muslim, soldier, return, city, genocide, attack, live, head, village, leave, member, right, turk, land, fight, murder, arm, group, place, carry, men, massacre, number, publish, million, organization, today, burn, report, army, political, new, try, force \n",
      "\n",
      "Topic 17: good, way, look, work, email, try, thing, new, year, drive, post, help, buy, really, question, day, problem, tell, run, best, ask, believe, people, sell, include, remember, sure, second, right, hear, case, bad, price, car, probably, great, bike, line, appreciate, game, play, little, hard, reply, able, address, set, mean, start, turn \n",
      "\n",
      "Topic 18: people, problem, good, work, cause, way, probably, question, post, look, thing, year, lot, new, point, believe, really, right, fact, sure, case, idea, group, day, try, read, ask, actually, program, number, ago, include, reason, change, study, person, result, test, quite, large, treatment, help, course, yes, able, certainly, tell, key, happen, great \n",
      "\n",
      "Topic 19: game, year, new, play, team, win, look, second, goal, division, post, great, good, leaf, period, john, ranger, wing, playoff, day, king, power, san, blue, lose, jose, hockey, remember, player, read, toronto, april, islander, nhl, list, follow, american, pittsburgh, star, patrick, night, email, gretzky, little, total, bad, sell, final, calgary, league \n",
      "\n",
      "Topic 20: good, look, new, car, people, way, work, thing, tell, try, year, drive, really, email, right, old, idea, buy, believe, help, sure, price, run, let, post, bit, read, follow, mean, number, power, day, little, long, problem, ask, great, write, base, big, talk, course, maybe, software, able, leave, company, standard, interested, best \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the top N words for each topic\n",
    "N_TOP_WORDS = 50\n",
    "\n",
    "ALL_TOPIC_WORDS = []\n",
    "for i in range(loaded_model.num_topics):\n",
    "    top_words_idx = word_topic_dist[i].argsort()[-N_TOP_WORDS:][::-1]\n",
    "    top_words = [loaded_model.id2word[idx] for idx in top_words_idx]\n",
    "\n",
    "    ALL_TOPIC_WORDS.append(top_words)\n",
    "\n",
    "    print(f\"Topic {i + 1}: {', '.join(top_words)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic = {}\n",
    "\n",
    "for topic_words in ALL_TOPIC_WORDS:\n",
    "  for word in topic_words:\n",
    "    if word in word_dic:\n",
    "      word_dic[word] = word_dic[word] + 1\n",
    "    else:\n",
    "      word_dic[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'window': 4,\n",
       " 'run': 11,\n",
       " 'file': 5,\n",
       " 'problem': 14,\n",
       " 'work': 17,\n",
       " 'program': 8,\n",
       " 'try': 17,\n",
       " 'look': 16,\n",
       " 'help': 11,\n",
       " 'write': 7,\n",
       " 'set': 7,\n",
       " 'windows': 3,\n",
       " 'way': 16,\n",
       " 'thing': 16,\n",
       " 'good': 16,\n",
       " 'error': 1,\n",
       " 'new': 18,\n",
       " 'line': 4,\n",
       " 'server': 1,\n",
       " 'question': 10,\n",
       " 'follow': 9,\n",
       " 'code': 1,\n",
       " 'application': 3,\n",
       " 'version': 4,\n",
       " 'color': 2,\n",
       " 'machine': 4,\n",
       " 'start': 8,\n",
       " 'driver': 3,\n",
       " 'manager': 1,\n",
       " 'image': 2,\n",
       " 'let': 8,\n",
       " 'change': 4,\n",
       " 'case': 10,\n",
       " 'display': 1,\n",
       " 'type': 1,\n",
       " 'screen': 1,\n",
       " 'appreciate': 3,\n",
       " 'directory': 1,\n",
       " 'create': 1,\n",
       " 'user': 1,\n",
       " 'tell': 12,\n",
       " 'bit': 8,\n",
       " 'client': 1,\n",
       " 'support': 3,\n",
       " 'different': 2,\n",
       " 'people': 14,\n",
       " 'number': 12,\n",
       " 'example': 3,\n",
       " 'command': 1,\n",
       " 'email': 9,\n",
       " 'year': 15,\n",
       " 'space': 2,\n",
       " 'research': 1,\n",
       " 'development': 1,\n",
       " 'science': 1,\n",
       " 'information': 5,\n",
       " 'world': 4,\n",
       " 'report': 2,\n",
       " 'provide': 3,\n",
       " 'cost': 3,\n",
       " 'base': 3,\n",
       " 'right': 15,\n",
       " 'center': 1,\n",
       " 'public': 3,\n",
       " 'high': 3,\n",
       " 'earth': 1,\n",
       " 'place': 3,\n",
       " 'send': 3,\n",
       " 'available': 5,\n",
       " 'date': 1,\n",
       " 'plan': 1,\n",
       " 'sure': 8,\n",
       " 'orbit': 1,\n",
       " 'international': 1,\n",
       " 'second': 4,\n",
       " 'contact': 1,\n",
       " 'money': 1,\n",
       " 'project': 1,\n",
       " 'april': 2,\n",
       " 'end': 4,\n",
       " 'include': 9,\n",
       " 'limit': 1,\n",
       " 'begin': 2,\n",
       " 'day': 10,\n",
       " 'press': 1,\n",
       " 'national': 2,\n",
       " 'material': 1,\n",
       " 'technology': 1,\n",
       " 'reach': 1,\n",
       " 'increase': 1,\n",
       " 'long': 7,\n",
       " 'analysis': 1,\n",
       " 'car': 4,\n",
       " 'really': 12,\n",
       " 'bike': 2,\n",
       " 'drive': 7,\n",
       " 'turn': 2,\n",
       " 'little': 7,\n",
       " 'point': 9,\n",
       " 'big': 4,\n",
       " 'lot': 6,\n",
       " 'far': 2,\n",
       " 'dod': 1,\n",
       " 'leave': 5,\n",
       " 'power': 6,\n",
       " 'probably': 8,\n",
       " 'bad': 6,\n",
       " 'rid': 1,\n",
       " 'buy': 8,\n",
       " 'post': 14,\n",
       " 'large': 2,\n",
       " 'road': 1,\n",
       " 'ride': 1,\n",
       " 'guy': 2,\n",
       " 'best': 5,\n",
       " 'mean': 10,\n",
       " 'head': 2,\n",
       " 'stuff': 1,\n",
       " 'maybe': 4,\n",
       " 'actually': 5,\n",
       " 'believe': 7,\n",
       " 'god': 2,\n",
       " 'reason': 4,\n",
       " 'life': 2,\n",
       " 'wrong': 1,\n",
       " 'agree': 1,\n",
       " 'word': 2,\n",
       " 'read': 9,\n",
       " 'live': 4,\n",
       " 'feel': 1,\n",
       " 'talk': 3,\n",
       " 'human': 1,\n",
       " 'true': 3,\n",
       " 'fact': 5,\n",
       " 'state': 3,\n",
       " 'understand': 1,\n",
       " 'idea': 3,\n",
       " 'argument': 1,\n",
       " 'course': 7,\n",
       " 'kill': 3,\n",
       " 'mind': 1,\n",
       " 'consider': 3,\n",
       " 'yes': 2,\n",
       " 'israel': 1,\n",
       " 'israeli': 1,\n",
       " 'country': 2,\n",
       " 'jew': 1,\n",
       " 'arab': 1,\n",
       " 'government': 4,\n",
       " 'war': 2,\n",
       " 'attack': 2,\n",
       " 'claim': 2,\n",
       " 'jewish': 1,\n",
       " 'palestinian': 1,\n",
       " 'land': 2,\n",
       " 'act': 1,\n",
       " 'peace': 1,\n",
       " 'stop': 1,\n",
       " 'group': 3,\n",
       " 'accept': 1,\n",
       " 'allow': 1,\n",
       " 'happen': 3,\n",
       " 'law': 3,\n",
       " 'policy': 1,\n",
       " 'american': 3,\n",
       " 'card': 4,\n",
       " 'computer': 3,\n",
       " 'disk': 3,\n",
       " 'video': 1,\n",
       " 'memory': 3,\n",
       " 'hard': 2,\n",
       " 'controller': 1,\n",
       " 'monitor': 1,\n",
       " 'software': 5,\n",
       " 'bus': 1,\n",
       " 'price': 5,\n",
       " 'interested': 3,\n",
       " 'scsi': 1,\n",
       " 'speed': 2,\n",
       " 'access': 1,\n",
       " 'sell': 6,\n",
       " 'data': 3,\n",
       " 'apple': 2,\n",
       " 'christian': 1,\n",
       " 'jesus': 1,\n",
       " 'bible': 1,\n",
       " 'christ': 1,\n",
       " 'church': 1,\n",
       " 'ask': 8,\n",
       " 'faith': 1,\n",
       " 'religion': 1,\n",
       " 'answer': 1,\n",
       " 'man': 1,\n",
       " 'belief': 1,\n",
       " 'book': 2,\n",
       " 'person': 3,\n",
       " 'christianity': 1,\n",
       " 'truth': 1,\n",
       " 'sin': 1,\n",
       " 'matter': 1,\n",
       " 'john': 2,\n",
       " 'scripture': 1,\n",
       " 'key': 2,\n",
       " 'encryption': 1,\n",
       " 'chip': 2,\n",
       " 'soon': 1,\n",
       " 'bank': 1,\n",
       " 'clipper': 1,\n",
       " 'secure': 1,\n",
       " 'phone': 1,\n",
       " 'gordon': 1,\n",
       " 'geb': 1,\n",
       " 'surrender': 1,\n",
       " 'intellect': 1,\n",
       " 'skepticism': 1,\n",
       " 'njxp': 1,\n",
       " 'chastity': 1,\n",
       " 'cadredslpittedu': 1,\n",
       " 'shameful': 1,\n",
       " 'security': 1,\n",
       " 'secret': 1,\n",
       " 'nsa': 1,\n",
       " 'encrypt': 1,\n",
       " 'escrow': 1,\n",
       " 'agency': 1,\n",
       " 'algorithm': 1,\n",
       " 'strong': 1,\n",
       " 'privacy': 1,\n",
       " 'mac': 2,\n",
       " 'mhz': 1,\n",
       " 'device': 1,\n",
       " 'fast': 1,\n",
       " 'university': 2,\n",
       " 'list': 3,\n",
       " 'ftp': 1,\n",
       " 'mail': 1,\n",
       " 'address': 3,\n",
       " 'copy': 1,\n",
       " 'advance': 3,\n",
       " 'internet': 1,\n",
       " 'archivename': 1,\n",
       " 'site': 1,\n",
       " 'various': 1,\n",
       " 'add': 1,\n",
       " 'source': 3,\n",
       " 'function': 1,\n",
       " 'require': 1,\n",
       " 'faq': 1,\n",
       " 'free': 1,\n",
       " 'anonymous': 1,\n",
       " 'unix': 1,\n",
       " 'info': 1,\n",
       " 'format': 1,\n",
       " 'print': 1,\n",
       " 'graphic': 1,\n",
       " 'hardware': 1,\n",
       " 'board': 1,\n",
       " 'box': 1,\n",
       " 'old': 3,\n",
       " 'great': 6,\n",
       " 'real': 1,\n",
       " 'game': 4,\n",
       " 'sound': 2,\n",
       " 'small': 1,\n",
       " 'kind': 1,\n",
       " 'gun': 1,\n",
       " 'control': 2,\n",
       " 'force': 2,\n",
       " 'crime': 1,\n",
       " 'issue': 1,\n",
       " 'care': 1,\n",
       " 'arm': 2,\n",
       " 'pay': 1,\n",
       " 'regard': 1,\n",
       " 'protect': 1,\n",
       " 'citizen': 1,\n",
       " 'president': 1,\n",
       " 'weapon': 1,\n",
       " 'federal': 1,\n",
       " 'note': 1,\n",
       " 'police': 1,\n",
       " 'team': 2,\n",
       " 'player': 2,\n",
       " 'play': 3,\n",
       " 'season': 1,\n",
       " 'league': 2,\n",
       " 'win': 2,\n",
       " 'score': 1,\n",
       " 'fan': 1,\n",
       " 'hockey': 2,\n",
       " 'hit': 1,\n",
       " 'baseball': 1,\n",
       " 'pick': 1,\n",
       " 'lose': 2,\n",
       " 'pitch': 1,\n",
       " 'home': 1,\n",
       " 'nhl': 2,\n",
       " 'watch': 1,\n",
       " 'ranger': 2,\n",
       " 'playoff': 2,\n",
       " 'average': 1,\n",
       " 'offer': 1,\n",
       " 'condition': 1,\n",
       " 'low': 1,\n",
       " 'model': 1,\n",
       " 'light': 1,\n",
       " 'sale': 1,\n",
       " 'radio': 1,\n",
       " 'design': 1,\n",
       " 'armenian': 1,\n",
       " 'child': 1,\n",
       " 'turkish': 1,\n",
       " 'serdar': 1,\n",
       " 'argic': 1,\n",
       " 'armenia': 1,\n",
       " 'away': 1,\n",
       " 'woman': 1,\n",
       " 'muslim': 1,\n",
       " 'soldier': 1,\n",
       " 'return': 1,\n",
       " 'city': 1,\n",
       " 'genocide': 1,\n",
       " 'village': 1,\n",
       " 'member': 1,\n",
       " 'turk': 1,\n",
       " 'fight': 1,\n",
       " 'murder': 1,\n",
       " 'carry': 1,\n",
       " 'men': 1,\n",
       " 'massacre': 1,\n",
       " 'publish': 1,\n",
       " 'million': 1,\n",
       " 'organization': 1,\n",
       " 'today': 1,\n",
       " 'burn': 1,\n",
       " 'army': 1,\n",
       " 'political': 1,\n",
       " 'remember': 2,\n",
       " 'hear': 1,\n",
       " 'reply': 1,\n",
       " 'able': 3,\n",
       " 'cause': 1,\n",
       " 'ago': 1,\n",
       " 'study': 1,\n",
       " 'result': 1,\n",
       " 'test': 1,\n",
       " 'quite': 1,\n",
       " 'treatment': 1,\n",
       " 'certainly': 1,\n",
       " 'goal': 1,\n",
       " 'division': 1,\n",
       " 'leaf': 1,\n",
       " 'period': 1,\n",
       " 'wing': 1,\n",
       " 'king': 1,\n",
       " 'san': 1,\n",
       " 'blue': 1,\n",
       " 'jose': 1,\n",
       " 'toronto': 1,\n",
       " 'islander': 1,\n",
       " 'pittsburgh': 1,\n",
       " 'star': 1,\n",
       " 'patrick': 1,\n",
       " 'night': 1,\n",
       " 'gretzky': 1,\n",
       " 'total': 1,\n",
       " 'final': 1,\n",
       " 'calgary': 1,\n",
       " 'company': 1,\n",
       " 'standard': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the author-topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the author_topic_matrix to get author-topic distribution\n",
    "\n",
    "# Compute the sum of rows in author_topic_matrix\n",
    "author_topic_sum = loaded_model.author_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Replace zero sums with a small epsilon value\n",
    "epsilon = 1e-10\n",
    "author_topic_sum[author_topic_sum == 0] = epsilon\n",
    "\n",
    "# Perform element-wise division\n",
    "author_topic_dist = loaded_model.author_topic_matrix / author_topic_sum\n",
    "\n",
    "# Visualize the top N topics for each author\n",
    "N_TOP_TOPICS = 3\n",
    "top_topics_list = []\n",
    "for i, author in enumerate(loaded_model.authors):\n",
    "    top_topics_idx = author_topic_dist[i].argsort()[-N_TOP_TOPICS:][::-1]\n",
    "    top_topics_list.append(top_topics_idx)\n",
    "    # print(f\"Author {i+1} => {author} : Topic IDs {top_topics_idx} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lerxst@wam.umd.edu (where's my thing)</td>\n",
       "      <td>[14, 19, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guykuo@carson.u.washington.edu (Guy Kuo)</td>\n",
       "      <td>[8, 5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twillis@ec.ecn.purdue.edu (Thomas E Willis)</td>\n",
       "      <td>[16, 11, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgreen@amber (Joe Green)</td>\n",
       "      <td>[6, 19, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcm@head-cfa.harvard.edu (Jonathan McDowell)</td>\n",
       "      <td>[14, 19, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>bchuang@css.itd.umich.edu (Ben Chuang)</td>\n",
       "      <td>[7, 19, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>shaig@composer.think.com (Shai Guday)</td>\n",
       "      <td>[4, 12, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>mrj@cs.su.oz.au (Mark James)</td>\n",
       "      <td>[19, 18, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>ebodin@pearl.tufts.edu</td>\n",
       "      <td>[5, 19, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>gunning@cco.caltech.edu (Kevin J. Gunning)</td>\n",
       "      <td>[0, 18, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5769 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           authors        topics\n",
       "0            lerxst@wam.umd.edu (where's my thing)   [14, 19, 8]\n",
       "1         guykuo@carson.u.washington.edu (Guy Kuo)    [8, 5, 10]\n",
       "2      twillis@ec.ecn.purdue.edu (Thomas E Willis)  [16, 11, 19]\n",
       "3                         jgreen@amber (Joe Green)   [6, 19, 18]\n",
       "4     jcm@head-cfa.harvard.edu (Jonathan McDowell)   [14, 19, 8]\n",
       "...                                            ...           ...\n",
       "5764        bchuang@css.itd.umich.edu (Ben Chuang)   [7, 19, 18]\n",
       "5765         shaig@composer.think.com (Shai Guday)   [4, 12, 19]\n",
       "5766                  mrj@cs.su.oz.au (Mark James)   [19, 18, 1]\n",
       "5767                        ebodin@pearl.tufts.edu   [5, 19, 18]\n",
       "5768    gunning@cco.caltech.edu (Kevin J. Gunning)    [0, 18, 1]\n",
       "\n",
       "[5769 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df = pd.DataFrame({'authors': loaded_model.authors, 'topics': top_topics_list})\n",
    "top_topics_of_authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>lmvec@westminster.ac.uk (William Hargreaves)</td>\n",
       "      <td>[18, 8, 19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           authors       topics\n",
       "2079  lmvec@westminster.ac.uk (William Hargreaves)  [18, 8, 19]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df[top_topics_of_authors_df['authors'] == 'lmvec@westminster.ac.uk (William Hargreaves)']\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMAGD - Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"admagd_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"trained_ model/{model_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_path}.pkl\", 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model_joblib = load(f\"{model_path}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract word for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you've run Gibbs sampling\n",
    "word_topic_matrix = loaded_model.word_topic_matrix\n",
    "word_topic_sum = word_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "word_topic_dist = word_topic_matrix / word_topic_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: like, just, use, know, apr, distribution, university, say, dod, good, make, work, thing, need, time, new, usa, want, look, year \n",
      "\n",
      "Topic 2: university, israel, say, know, just, apr, like, state, israeli, right, year, use, jew, arab, make, time, want, world, way, jewish \n",
      "\n",
      "Topic 3: use, university, know, like, just, need, work, thanks, problem, want, computer, good, distribution, time, help, run, try, replyto, drive, apr \n",
      "\n",
      "Topic 4: university, use, like, know, just, work, time, need, new, distribution, thanks, say, good, look, want, make, try, usa, problem, question \n",
      "\n",
      "Topic 5: say, just, government, use, like, state, make, know, gun, right, time, university, way, distribution, apr, good, day, thing, law, want \n",
      "\n",
      "Topic 6: university, use, know, distribution, thanks, email, like, computer, look, just, apr, new, work, usa, want, science, problem, time, help, need \n",
      "\n",
      "Topic 7: university, know, just, like, use, good, say, time, apr, distribution, want, new, look, car, make, year, computer, need, way, right \n",
      "\n",
      "Topic 8: use, university, program, like, know, version, work, email, thanks, need, new, help, file, software, distribution, look, available, run, window, just \n",
      "\n",
      "Topic 9: say, university, know, make, just, like, case, apr, thing, use, time, mean, way, world, point, want, god, opinion, distribution, right \n",
      "\n",
      "Topic 10: university, know, like, distribution, just, use, look, email, make, new, good, need, want, thanks, time, replyto, year, work, say, usa \n",
      "\n",
      "Topic 11: game, university, team, play, year, like, win, good, player, time, apr, say, just, know, come, make, fan, season, hockey, look \n",
      "\n",
      "Topic 12: university, use, know, apr, just, distribution, like, message, say, gmt, make, work, xnewsreader, inreplyto, look, try, write, time, good, way \n",
      "\n",
      "Topic 13: university, say, just, like, know, god, time, come, apr, thing, good, make, right, want, way, use, look, tell, year, point \n",
      "\n",
      "Topic 14: know, like, university, use, say, just, good, time, science, make, problem, replyto, apr, way, try, computer, question, thing, look, univ \n",
      "\n",
      "Topic 15: world, long, distribution, way, work, today, government, close, time, state, year, turkish, single, pass, serve, replyto, road, say, exist, armenian \n",
      "\n",
      "Topic 16: university, use, distribution, know, thanks, email, like, just, work, new, drive, usa, need, computer, problem, world, want, apr, sale, make \n",
      "\n",
      "Topic 17: university, like, say, just, know, apr, good, use, new, time, distribution, thing, look, make, state, year, come, want, work, way \n",
      "\n",
      "Topic 18: use, university, know, window, problem, thanks, like, work, just, run, need, file, email, program, look, try, computer, make, help, version \n",
      "\n",
      "Topic 19: use, chip, clipper, key, just, encryption, know, like, work, distribution, government, university, make, say, good, netcomcom, new, need, information, time \n",
      "\n",
      "Topic 20: say, god, know, just, like, christian, time, come, make, way, good, thing, mean, point, jesus, use, question, want, university, word \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the top N words for each topic\n",
    "N_TOP_WORDS = 20\n",
    "for i in range(loaded_model.num_topics):\n",
    "    top_words_idx = word_topic_dist[i].argsort()[-N_TOP_WORDS:][::-1]\n",
    "    top_words = [loaded_model.id2word[idx] for idx in top_words_idx]\n",
    "    print(f\"Topic {i + 1}: {', '.join(top_words)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the author-topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the author_topic_matrix to get author-topic distribution\n",
    "\n",
    "# Compute the sum of rows in author_topic_matrix\n",
    "author_topic_sum = loaded_model.author_topic_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Replace zero sums with a small epsilon value\n",
    "epsilon = 1e-10\n",
    "author_topic_sum[author_topic_sum == 0] = epsilon\n",
    "\n",
    "# Perform element-wise division\n",
    "author_topic_dist = loaded_model.author_topic_matrix / author_topic_sum\n",
    "\n",
    "# Visualize the top N topics for each author\n",
    "N_TOP_TOPICS = 2\n",
    "top_topics_list = []\n",
    "for i, author in enumerate(loaded_model.authors):\n",
    "    top_topics_idx = author_topic_dist[i].argsort()[-N_TOP_TOPICS:][::-1]\n",
    "    top_topics_list.append(top_topics_idx)\n",
    "    # print(f\"Author {i+1} => {author} : Topic IDs {top_topics_idx} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mamatha Devineni Ratnam</td>\n",
       "      <td>[10, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)</td>\n",
       "      <td>[5, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hilmi-er@dsv.su.se (Hilmi Eren)</td>\n",
       "      <td>[1, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guyd@austin.ibm.com (Guy Dawson)</td>\n",
       "      <td>[2, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander Samuel McDiarmid</td>\n",
       "      <td>[2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>pcarmack@gimp.kpc.com (Phil Carmack)</td>\n",
       "      <td>[5, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>gt5735a@prism.gatech.EDU (Mark Devaney)</td>\n",
       "      <td>[0, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>pkeenan@s.psych.uiuc.edu (Patricia Keenan)</td>\n",
       "      <td>[10, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8532</th>\n",
       "      <td>CCMB</td>\n",
       "      <td>[0, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>shaig@composer.think.com (Shai Guday)</td>\n",
       "      <td>[1, 19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                authors    topics\n",
       "0                               Mamatha Devineni Ratnam  [10, 19]\n",
       "1     mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)   [5, 19]\n",
       "2                       hilmi-er@dsv.su.se (Hilmi Eren)   [1, 14]\n",
       "3                      guyd@austin.ibm.com (Guy Dawson)   [2, 15]\n",
       "4                            Alexander Samuel McDiarmid    [2, 5]\n",
       "...                                                 ...       ...\n",
       "8529               pcarmack@gimp.kpc.com (Phil Carmack)   [5, 19]\n",
       "8530            gt5735a@prism.gatech.EDU (Mark Devaney)   [0, 18]\n",
       "8531         pkeenan@s.psych.uiuc.edu (Patricia Keenan)  [10, 19]\n",
       "8532                                               CCMB   [0, 18]\n",
       "8533              shaig@composer.think.com (Shai Guday)   [1, 19]\n",
       "\n",
       "[8534 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics_of_authors_df = pd.DataFrame({'authors': loaded_model.authors, 'topics': top_topics_list})\n",
    "top_topics_of_authors_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
